{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"API_tweet_scraping.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPiYtPpxIO9t6zWnnYhoUz5"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"-MEOE6vaIIUH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1596966374218,"user_tz":-120,"elapsed":595,"user":{"displayName":"luca lamoni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZMpGjRPw1MibJF_PsAz5kbsPgPkSGpE7n4w8mKQ=s64","userId":"07353226337550152050"}},"outputId":"592487a5-4101-4f4a-99bb-9c4faa131fd1"},"source":["# Mount Google Drive\n","from google.colab import drive # import drive from google colab\n","\n","ROOT = \"/content/drive\"     # default location for the drive\n","print(ROOT)                 # print content of ROOT (Optional)\n","\n","drive.mount(ROOT)           # we mount the google drive at /content/drive\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V10vhmK4IU80","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596966379188,"user_tz":-120,"elapsed":567,"user":{"displayName":"luca lamoni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZMpGjRPw1MibJF_PsAz5kbsPgPkSGpE7n4w8mKQ=s64","userId":"07353226337550152050"}},"outputId":"fd17a2f6-68b2-48bd-904a-9b33323d26a0"},"source":["# Change directory in google drive\n","%cd '//content//drive//My Drive/Colab Notebooks//'"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RYcVh0_cIcXI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596966382258,"user_tz":-120,"elapsed":568,"user":{"displayName":"luca lamoni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZMpGjRPw1MibJF_PsAz5kbsPgPkSGpE7n4w8mKQ=s64","userId":"07353226337550152050"}}},"source":["#import pacjages\n","import os\n","import time\n","import json\n","import pandas as pd\n","import tweepy\n","import datetime"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pld_12D6HFRn","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596966386996,"user_tz":-120,"elapsed":579,"user":{"displayName":"luca lamoni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZMpGjRPw1MibJF_PsAz5kbsPgPkSGpE7n4w8mKQ=s64","userId":"07353226337550152050"}}},"source":["# this was taken from https://towardsdatascience.com/tweepy-for-beginners-24baf21f2c25, it uses a class to create the api and define the things we want to extract. Right now I have used my \n","#API credentials but we need to change this using Rob method\n","class TweetMiner(object):\n","\n","    result_limit    =   20    \n","    data            =   []\n","    api             =   False\n","    \n","    twitter_keys = {\n","        'consumer_key':        'iwvyIvriy0AwHR0T7n1AfJJDi',\n","        'consumer_secret':     '8A3UbQzrOmLKq9hhTwghp0oH4uga0p84GDNNiqeCR7gAhc0JPH',\n","        'access_token_key':    '1291308136679317504-opzlc5uR8yPUOYf5xtB07KVaOFKE7U',\n","        'access_token_secret': 'n0fQkOk7atzzYksXXtiyVcN9B8Wc3LukVhdA2wKt9rsDH'\n","    }\n","    \n","    \n","    def __init__(self, keys_dict=twitter_keys, api=api, result_limit = 20):\n","        \n","        self.twitter_keys = keys_dict\n","        \n","        auth = tweepy.OAuthHandler(keys_dict['consumer_key'], keys_dict['consumer_secret'])\n","        auth.set_access_token(keys_dict['access_token_key'], keys_dict['access_token_secret'])\n","        \n","        self.api = tweepy.API(auth)\n","        self.twitter_keys = keys_dict\n","        \n","        self.result_limit = result_limit\n","        \n","\n","    def mine_user_tweets(self, user=\"dril\", #BECAUSE WHO ELSE!\n","                         mine_rewteets=False,\n","                         max_pages=5):\n","\n","        data           =  []\n","        last_tweet_id  =  False\n","        page           =  1\n","        \n","        while page <= max_pages:\n","            if last_tweet_id:\n","                statuses   =   self.api.user_timeline(screen_name=user,\n","                                                     count=self.result_limit,\n","                                                     max_id=last_tweet_id - 1,\n","                                                     tweet_mode = 'extended',\n","                                                     include_retweets=True\n","                                                    )        \n","            else:\n","                statuses   =   self.api.user_timeline(screen_name=user,\n","                                                        count=self.result_limit,\n","                                                        tweet_mode = 'extended',\n","                                                        include_retweets=True)\n","                \n","            for item in statuses:\n","\n","                mined = {\n","                    'tweet_id':        item.id,\n","                    'name':            item.user.name,\n","                    'screen_name':     item.user.screen_name,\n","                    'retweet_count':   item.retweet_count,\n","                    'text':            item.full_text,\n","                    'mined_at':        datetime.datetime.now(),\n","                    'created_at':      item.created_at,\n","                    'favourite_count': item.favorite_count,\n","                    'hashtags':        item.entities['hashtags'],\n","                    'status_count':    item.user.statuses_count,\n","                    'location':        item.place,\n","                    'source_device':   item.source,\n","                    'user_description':item.user.description,\n","                    'user_friends_n':  item.user.friends_count,\n","                    'user_followers_n':item.user.followers_count   \n","                }\n","                \n","                try:\n","                    mined['retweet_text'] = item.retweeted_status.full_text\n","                except:\n","                    mined['retweet_text'] = 'None'\n","                try:\n","                    mined['quote_text'] = item.quoted_status.full_text\n","                    mined['quote_screen_name'] = status.quoted_status.user.screen_name\n","                except:\n","                    mined['quote_text'] = 'None'\n","                    mined['quote_screen_name'] = 'None'\n","                \n","                last_tweet_id = item.id\n","                data.append(mined)\n","                \n","            page += 1\n","            \n","        return data"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"8JCq_dcSJDL2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596981665367,"user_tz":-120,"elapsed":3580,"user":{"displayName":"luca lamoni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZMpGjRPw1MibJF_PsAz5kbsPgPkSGpE7n4w8mKQ=s64","userId":"07353226337550152050"}}},"source":["#now use the scraping function to get a list of journalist twitter handles based on a keyword\n","%run LL_function_to_scrape_journalists_webpage.ipynb\n","twitter_handles = scrape_journalist_website('cyber')\n","users = twitter_handles['twitter_handle']"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"VxrRnIsJJMPu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596981677158,"user_tz":-120,"elapsed":614,"user":{"displayName":"luca lamoni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZMpGjRPw1MibJF_PsAz5kbsPgPkSGpE7n4w8mKQ=s64","userId":"07353226337550152050"}}},"source":["#initialize the class\n","miner=TweetMiner(result_limit = 200)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"_ZpI0wVnJTRv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596963845148,"user_tz":-120,"elapsed":7123,"user":{"displayName":"luca lamoni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZMpGjRPw1MibJF_PsAz5kbsPgPkSGpE7n4w8mKQ=s64","userId":"07353226337550152050"}}},"source":["#mined_tweets = miner.mine_user_tweets(user=USER, max_pages=17)\n","\n","#mined_tweets_df= pd.DataFrame(mined_tweets)"],"execution_count":85,"outputs":[]},{"cell_type":"code","metadata":{"id":"859RGzpiMZdF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596981760564,"user_tz":-120,"elapsed":78801,"user":{"displayName":"luca lamoni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZMpGjRPw1MibJF_PsAz5kbsPgPkSGpE7n4w8mKQ=s64","userId":"07353226337550152050"}}},"source":["# this is taken from the same website, it basically run the scraping on a list of users\n","# there is a part where it pauses of it gets some errors (probably due to API tweets limits)\n","#probably that part can be modified or tweaked to work better.\n","import time\n","\n","handle_list= list(users)\n","\n","twitter_dict={}\n","counter=0\n","\n","for name in handle_list:\n","    try:\n","      twitter_dict[name]=[]\n","      twitter_dict[name].append(miner.mine_user_tweets(user=name, max_pages=17))\n","      counter = counter +1\n","\n","      if counter%40==0:\n","        time.sleep(900) #15 minute sleep time\n","    #if name invalid print name and remove key\n","    except:\n","      print(name, 'is invalid or locked')\n","      twitter_dict.pop(name)\n","    \n","    \n","all_tweets=pd.concat([pd.DataFrame(twitter_dict[i][0]) for i in twitter_dict])"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"HHkq2iCheb79","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596982454949,"user_tz":-120,"elapsed":710,"user":{"displayName":"luca lamoni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZMpGjRPw1MibJF_PsAz5kbsPgPkSGpE7n4w8mKQ=s64","userId":"07353226337550152050"}},"outputId":"166cbbd1-beb6-4b05-924c-66acf8f03bb2"},"source":["#check the dataframe\n","all_tweets.shape"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(27879, 18)"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"tNJ4jjSOe0bM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596982468257,"user_tz":-120,"elapsed":1570,"user":{"displayName":"luca lamoni","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiZMpGjRPw1MibJF_PsAz5kbsPgPkSGpE7n4w8mKQ=s64","userId":"07353226337550152050"}}},"source":["# save CSV file\n","all_tweets.to_csv(r'//content//drive//My Drive/Colab Notebooks//cyber_tweets.csv')"],"execution_count":33,"outputs":[]}]}