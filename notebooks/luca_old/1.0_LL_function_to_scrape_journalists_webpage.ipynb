{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O1X3dWi0oEKQ"
   },
   "source": [
    "## **Function for scraping twitter handles of journalists based on a specific keyword**\n",
    "Date 06/08/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 704,
     "status": "ok",
     "timestamp": 1596698355302,
     "user": {
      "displayName": "luca lamoni",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiZMpGjRPw1MibJF_PsAz5kbsPgPkSGpE7n4w8mKQ=s64",
      "userId": "07353226337550152050"
     },
     "user_tz": -120
    },
    "id": "57NUlz13_w3G"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "# Note we need to check library version\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "812HEzr5AE8t"
   },
   "outputs": [],
   "source": [
    "def scrape_journalist_website(keyword):\n",
    "  \"\"\"\n",
    "  This function scrapes a specific web page that contains information about journalists based in the UK\n",
    "  who have a presence on Twitter. The fuction takes 1 argument which is the keyword that help us filter the journalists\n",
    "  based on their field of expertise\n",
    "  \"\"\"\n",
    "  # Set the url search=keyword\n",
    "  url = r\"https://www.journalism.co.uk/prof/?search=\" + keyword + \"&chunk=0&cmd=default\"\n",
    "  html = urlopen(url)\n",
    "\n",
    "  # create two empty lists to store results\n",
    "  profile_handles_page = []\n",
    "  twitter_profile_names = []\n",
    "  \n",
    "  # create the loop that goes through the number of pages\n",
    "  check = False\n",
    "  i = 0\n",
    "  while not check:\n",
    "    # Define specific page url\n",
    "    page_url = r\"https://www.journalism.co.uk/prof/?search=\" + keyword + \"&chunk=\" + str(i) + \"&cmd=default\"\n",
    "    html = urlopen(page_url)\n",
    "\n",
    "    # Parse the webpage \n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Create an empty list and fill it with a specific sub set of the web page that contains journalists' information\n",
    "    temp_content_list = []\n",
    "    for x in soup.find_all('div', class_=\"holder\"):\n",
    "      temp_content_list.append(x)\n",
    "      \n",
    "      # Find within the subsett all twitter handles\n",
    "      profile_handles_page = re.findall(r'@(\\w+)', str(temp_content_list))\n",
    "\n",
    "    # Each keyword will produce different number of journalists (i.e. differnt number of pages)\n",
    "    # Since we are not sure how many pages we need to scrap (if we set a high fixed number beforehand, we are redirected to the last page of the search)\n",
    "    # So to avoid repetions of twitter handles we check if any of the twittr handles we are appending is already present in twitter_profile_names\n",
    "    # if it is we break the loop and return our list as a Pandas dataframe\n",
    "    check =  any(item in profile_handles_page for item in twitter_profile_names)\n",
    "    if check is False:\n",
    "      for twitter_handle in profile_handles_page:\n",
    "        twitter_profile_names.append(twitter_handle)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "  \n",
    "  return pd.DataFrame(twitter_profile_names, columns = ['twitter_handle'])\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNuABM5VWQ55kjDy/NmXGib",
   "collapsed_sections": [],
   "name": "1.0_LL_function_to_scrape_journalists_webpage.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
