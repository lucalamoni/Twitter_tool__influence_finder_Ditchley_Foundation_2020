{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Ditchley S2DS project August 2020 - Code Pipeline<h1>\n",
    "    <h2>Team: Adam Hawken, Luca Lamoni, Elizabeth Nicholson, Robert Webster<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#![]() #graphical representation of the pipeline here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Section 0: Working directory and graph DB setup<h3>\n",
    "    <h4>0.1: Modules and working directory setup<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory & sub-directories already exist, skipping.\n"
     ]
    }
   ],
   "source": [
    "# Import modules and set up working directory\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import json\n",
    "import csv\n",
    "import threading\n",
    "import queue\n",
    "import asyncio \n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import twint\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Set up working directory\n",
    "# The working directory should reflect the structure of the Github repository https://github.com/S2DSLondon/Aug20_Ditchley\n",
    "sys.path.insert(1, '/Users/adam/S2DS/GitHub/Aug20_Ditchley')\n",
    "from src.data import pipeline_setup\n",
    "pipeline_setup.build_data_dir('/Users/adam/S2DS/GitHub/Aug20_Ditchley')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>0.2: Initialize graph database<h4> \n",
    "\n",
    "Databse must be active, this can be done in the neo4j desktop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from py2neo import Graph\n",
    "from py2neo.data import Node, Relationship\n",
    "from src.graph_database import graphdb as gdb\n",
    "\n",
    "# load / declare the database\n",
    "graph = gdb.get_graph(new_graph = True)\n",
    "graph\n",
    "# start with an empty graph\n",
    "graph.delete_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Section 1: Getting journalist twitter handles according to a keyword<h3>\n",
    "    <h4>The journalist scraping is performed at the web address https://www.journalism.co.uk/prof/?chunk=0&cmd=default<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose keyword and run the scraping function\n",
    "from src.data import journalists as journos\n",
    "keyword = 'cybersecurity'\n",
    "# Input: string / Output: list\n",
    "journo_handles = journos.get_handles_by_keyword(keyword)\n",
    "print(len(journo_handles))\n",
    "type(journo_handles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Section 2. Scrape user information and friend lists for each journalist in the list<h3>\n",
    "    <h4>2.1: Scrape user information using the Twitter API<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load twitter API credentials and return a tweepy API instance\n",
    "import json\n",
    "import tweepy\n",
    "from src.data import api_tweepy as api\n",
    "\n",
    "# Input: path of json file with credentials / Output: tweepy.api.API\n",
    "tw_api = api.connect_API('../src/data/twitter_credentials.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_friends_n</th>\n",
       "      <th>user_followers_n</th>\n",
       "      <th>prof_created_at</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>statuses_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>335773502</td>\n",
       "      <td>_lucyingham</td>\n",
       "      <td>Lucy Ingham</td>\n",
       "      <td>London</td>\n",
       "      <td>editor of and digital magazines verdict magazi...</td>\n",
       "      <td>516</td>\n",
       "      <td>647</td>\n",
       "      <td>2011-07-15 06:29:08</td>\n",
       "      <td>2210</td>\n",
       "      <td>False</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>964233746865119233</td>\n",
       "      <td>jesscahaworth</td>\n",
       "      <td>Jessica Haworth</td>\n",
       "      <td></td>\n",
       "      <td>cybersecurity journalist at music buff and ski...</td>\n",
       "      <td>970</td>\n",
       "      <td>668</td>\n",
       "      <td>2018-02-15 20:23:34</td>\n",
       "      <td>459</td>\n",
       "      <td>False</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1186245031507693574</td>\n",
       "      <td>ad_nauseum74</td>\n",
       "      <td>Adam Bannister</td>\n",
       "      <td></td>\n",
       "      <td>journalist the daily swig cybersecurity</td>\n",
       "      <td>368</td>\n",
       "      <td>135</td>\n",
       "      <td>2019-10-21 11:38:12</td>\n",
       "      <td>114</td>\n",
       "      <td>False</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_id    screen_name             name location  \\\n",
       "0            335773502    _lucyingham      Lucy Ingham   London   \n",
       "1   964233746865119233  jesscahaworth  Jessica Haworth            \n",
       "2  1186245031507693574   ad_nauseum74   Adam Bannister            \n",
       "\n",
       "                                    user_description  user_friends_n  \\\n",
       "0  editor of and digital magazines verdict magazi...             516   \n",
       "1  cybersecurity journalist at music buff and ski...             970   \n",
       "2            journalist the daily swig cybersecurity             368   \n",
       "\n",
       "   user_followers_n     prof_created_at  favourites_count  verified  \\\n",
       "0               647 2011-07-15 06:29:08              2210     False   \n",
       "1               668 2018-02-15 20:23:34               459     False   \n",
       "2               135 2019-10-21 11:38:12               114     False   \n",
       "\n",
       "   statuses_count  \n",
       "0             456  \n",
       "1             583  \n",
       "2             277  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape user information using the API\n",
    "from src.data import api_user_tools as api_tools\n",
    "from src.data import data_cleanup as dc\n",
    "\n",
    "# Input: tweepy.api.API,list / Output: list\n",
    "api_users = api_tools.batch_request_user_info(tw_api,journo_handles)\n",
    "# Input: list / Output: DataFrame\n",
    "df_api = dc.populate_user_df(api_users)\n",
    "# Check\n",
    "df_api.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe as csv\n",
    "df_api.to_csv('../data/processed/'+keyword+'_user_profiles.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2.2: Load user info into graph DB<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in user information and drawing (Person) nodes\n"
     ]
    }
   ],
   "source": [
    "# Neo4j import files need to be in a specific folder, however, the csv files saved above are in a different folder, to go around this problem on Windows machines it is\n",
    "# possible to create a shortcut between the two folders\n",
    "\n",
    "# lowd in user information\n",
    "print('Loading in user information and drawing (Person) nodes')\n",
    "fn_users = 'processed/'+keyword+'_user_profiles.csv'\n",
    "gdb.load_users(fn_users ,graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2.3: Scrape user friend list using Twint<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt #1 to get friends of @_lucyinghamAttempt #1 to get friends of @JesscaHaworth\n",
      "\n",
      "Attempt #1 to get friends of @Ad_Nauseum74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n",
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n",
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n",
      "CRITICAL:root:twint.feed:Follow:IndexError\n",
      "CRITICAL:root:twint.feed:Follow:IndexError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for @Ad_Nauseum74 saved to: ../data/raw/cybersecurity_friends_Ad_Nauseum74.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.feed:Follow:IndexError\n",
      "CRITICAL:root:twint.feed:Follow:IndexError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for @_lucyingham saved to: ../data/raw/cybersecurity_friends__lucyingham.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.feed:Follow:IndexError\n",
      "CRITICAL:root:twint.feed:Follow:IndexError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for @JesscaHaworth saved to: ../data/raw/cybersecurity_friends_JesscaHaworth.csv\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "from src.data import twint_tools as tt\n",
    "\n",
    "# define keyword arguments / 'n_retries' = max number of scrape attempts, 'suppress' = hide critical Twint warnings\n",
    "kwargs = {'n_retries':3,\n",
    "         'suppress':False}\n",
    "# Multi threading function Input: _get_friends function, number of threads to distribute the queque, args and kwargs\n",
    "tt.twint_in_queue(tt._get_friends, 3, journo_handles, args=('../data/raw/'+keyword+'_',), kwargs=kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@_lucyingham follows 1548 users.\n",
      "@JesscaHaworth follows 3880 users.\n",
      "@Ad_Nauseum74 follows 1839 users.\n",
      "\n",
      "Total number of handles pulled: 7267\n",
      "Number of unique twitter handles: 1716\n",
      "\n",
      "Zero following in list for users: []\n"
     ]
    }
   ],
   "source": [
    "from src.data import twint_tools as tt\n",
    "# Concatenate all the individual lists into one dataframe with journalist and its friends\n",
    "friends_csv = tt.join_friends_csv(journo_handles,keyword) # this function has a bug, the first friend name is 'username'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe as csv\n",
    "friends_csv.to_csv('../data/processed/'+keyword+'_journalist_friends.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers\n",
    "\n",
    "Assume friends and followers are lognormally distributed, calculate the chi squared of each user and remove outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get user profiles of friends\n",
    "api_users = api_tools.batch_request_user_info(tw_api,list(friends_csv['friend']))                                                         \n",
    "df_api = dc.populate_user_df(api_users)\n",
    "\n",
    "# save user profiles to file\n",
    "df_api.to_csv('../data/processed/'+keyword+'_all_profiles.csv', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/anaconda3/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['plt']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1230e8080>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate chi2s\n",
    "%pylab\n",
    "no_loners = gdb.get_chi2(df_api)\n",
    "\n",
    "inliers = no_loners[no_loners['chi2']<6.18]\n",
    "outliers = no_loners[no_loners['chi2']>6.18]\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "plt.scatter(inliers['user_friends_n'],inliers['user_followers_n'],label='inliers')\n",
    "plt.scatter(outliers['user_friends_n'],outliers['user_followers_n'],label='outliers')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('user_friends_n')\n",
    "plt.ylabel('user_followers_n')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2.4: Load friend information into DB<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in friends info and drawing [FOLLOWS] edges\n"
     ]
    }
   ],
   "source": [
    "# load in friend information\n",
    "print('Loading in friends info and drawing [FOLLOWS] edges')\n",
    "fn_friends = 'processed/'+keyword+'_journalist_friends.csv'\n",
    "gdb.load_friends(fn_friends,graph,new=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload profile information of friends\n",
    "gdb.load_existing_users('processed/'+keyword+'_all_profiles.csv',graph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#excise outliers from database\n",
    "gdb.excise_outliers(outliers['screen_name'],graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter graph by keywords\n",
    "\n",
    "Look for keywords in the bio and screen name of friends, filter users who have these keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778\n"
     ]
    }
   ],
   "source": [
    "keywords = ['tech','security','artificial','machine', 'cyber', 'computer','code','hack']\n",
    "not_techies = gdb.filter_users_by_keywords(keywords,graph,without=True)\n",
    "print(len(not_techies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excise uninteresting profiles\n",
    "gdb.excise_outliers(not_techies['screen name'],graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Section 3. Loop over selected journalists handles and scrape their tweets (3.1) and mentions (3.2) using Twint<h3>\n",
    "    <h4>Section 3.1: Scrape tweets using Twint<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt #1 to get tweets of @_lucyinghamAttempt #1 to get tweets of @JesscaHaworthAttempt #1 to get tweets of @Ad_Nauseum74\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n",
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n",
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for @Ad_Nauseum74 saved to: ../data/raw/cybersecurity_tweets_Ad_Nauseum74.csv\n",
      "Results for @JesscaHaworth saved to: ../data/raw/cybersecurity_tweets_JesscaHaworth.csv\n",
      "Results for @_lucyingham saved to: ../data/raw/cybersecurity_tweets__lucyingham.csv\n"
     ]
    }
   ],
   "source": [
    "from src.data import twint_tools as tt\n",
    "# define keyword arguments\n",
    "kwargs = {'date_range':('2020-08-01 00:00:00', None),\n",
    "         'n_retries':3,\n",
    "         'suppress':False}\n",
    "# multi threading\n",
    "tt.twint_in_queue(tt._search_tweets_by_user, 3, journo_handles, args=('../data/raw/'+keyword+'_',), kwargs=kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>geo</th>\n",
       "      <th>source</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1299059177474732034</td>\n",
       "      <td>1299059177474732034</td>\n",
       "      <td>1598554817000</td>\n",
       "      <td>2020-08-27</td>\n",
       "      <td>21:00:17</td>\n",
       "      <td>CEST</td>\n",
       "      <td>335773502</td>\n",
       "      <td>_lucyingham</td>\n",
       "      <td>Lucy Ingham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'user_id': '335773502', 'username': '_lucyin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1299057580774432770</td>\n",
       "      <td>1299057580774432770</td>\n",
       "      <td>1598554437000</td>\n",
       "      <td>2020-08-27</td>\n",
       "      <td>20:53:57</td>\n",
       "      <td>CEST</td>\n",
       "      <td>335773502</td>\n",
       "      <td>_lucyingham</td>\n",
       "      <td>Lucy Ingham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'user_id': '335773502', 'username': '_lucyin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1298287471004983296</td>\n",
       "      <td>1298282082746216449</td>\n",
       "      <td>1598370828000</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>17:53:48</td>\n",
       "      <td>CEST</td>\n",
       "      <td>335773502</td>\n",
       "      <td>_lucyingham</td>\n",
       "      <td>Lucy Ingham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'user_id': '335773502', 'username': '_lucyin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1298141120128524288</td>\n",
       "      <td>1298131556251262976</td>\n",
       "      <td>1598335935000</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>08:12:15</td>\n",
       "      <td>CEST</td>\n",
       "      <td>335773502</td>\n",
       "      <td>_lucyingham</td>\n",
       "      <td>Lucy Ingham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'user_id': '335773502', 'username': '_lucyin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1298136447258697728</td>\n",
       "      <td>1298131556251262976</td>\n",
       "      <td>1598334821000</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>07:53:41</td>\n",
       "      <td>CEST</td>\n",
       "      <td>335773502</td>\n",
       "      <td>_lucyingham</td>\n",
       "      <td>Lucy Ingham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'user_id': '335773502', 'username': '_lucyin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id      conversation_id     created_at        date  \\\n",
       "0  1299059177474732034  1299059177474732034  1598554817000  2020-08-27   \n",
       "1  1299057580774432770  1299057580774432770  1598554437000  2020-08-27   \n",
       "2  1298287471004983296  1298282082746216449  1598370828000  2020-08-25   \n",
       "3  1298141120128524288  1298131556251262976  1598335935000  2020-08-25   \n",
       "4  1298136447258697728  1298131556251262976  1598334821000  2020-08-25   \n",
       "\n",
       "       time timezone    user_id     username         name  place    ...      \\\n",
       "0  21:00:17     CEST  335773502  _lucyingham  Lucy Ingham    NaN    ...       \n",
       "1  20:53:57     CEST  335773502  _lucyingham  Lucy Ingham    NaN    ...       \n",
       "2  17:53:48     CEST  335773502  _lucyingham  Lucy Ingham    NaN    ...       \n",
       "3  08:12:15     CEST  335773502  _lucyingham  Lucy Ingham    NaN    ...       \n",
       "4  07:53:41     CEST  335773502  _lucyingham  Lucy Ingham    NaN    ...       \n",
       "\n",
       "  geo source user_rt_id user_rt  retweet_id  \\\n",
       "0 NaN    NaN        NaN     NaN         NaN   \n",
       "1 NaN    NaN        NaN     NaN         NaN   \n",
       "2 NaN    NaN        NaN     NaN         NaN   \n",
       "3 NaN    NaN        NaN     NaN         NaN   \n",
       "4 NaN    NaN        NaN     NaN         NaN   \n",
       "\n",
       "                                            reply_to  retweet_date translate  \\\n",
       "0  [{'user_id': '335773502', 'username': '_lucyin...           NaN       NaN   \n",
       "1  [{'user_id': '335773502', 'username': '_lucyin...           NaN       NaN   \n",
       "2  [{'user_id': '335773502', 'username': '_lucyin...           NaN       NaN   \n",
       "3  [{'user_id': '335773502', 'username': '_lucyin...           NaN       NaN   \n",
       "4  [{'user_id': '335773502', 'username': '_lucyin...           NaN       NaN   \n",
       "\n",
       "  trans_src trans_dest  \n",
       "0       NaN        NaN  \n",
       "1       NaN        NaN  \n",
       "2       NaN        NaN  \n",
       "3       NaN        NaN  \n",
       "4       NaN        NaN  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joined all the individual csv into one dataframe\n",
    "cyber_test = tt.join_tweet_csv(journo_handles, keyword)\n",
    "# Check\n",
    "cyber_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe as csv\n",
    "cyber_test.to_csv('../data/processed/'+keyword+'_journalist_tweets_twint.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Section 3.2: Extract mentions from Twint dataset<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1298287471004983296</td>\n",
       "      <td>trypewriter01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1298287471004983296</td>\n",
       "      <td>berenicejbaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1298141120128524288</td>\n",
       "      <td>delafina777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1298136447258697728</td>\n",
       "      <td>delafina777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1298015000519487490</td>\n",
       "      <td>berenicejbaker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id        mentions\n",
       "0  1298287471004983296   trypewriter01\n",
       "1  1298287471004983296  berenicejbaker\n",
       "2  1298141120128524288     delafina777\n",
       "3  1298136447258697728     delafina777\n",
       "4  1298015000519487490  berenicejbaker"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data import data_cleanup as dc\n",
    "# from the twint dataset, extract mentions based on tweet id and save in a separate csv\n",
    "mentions_twint  = dc.mentions_to_df(cyber_test)\n",
    "# Check\n",
    "mentions_twint.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe\n",
    "mentions_twint.to_csv('../data/processed/' + keyword + '_mentions_twint.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Section 4. Loop over selected journalists handles and scrape their tweets (4.1) and mentions (4.2) using Twitter API<h3>\n",
    "    <h4>Section 4.1: Scrape tweets using Twitter API<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tweepy\n",
    "from src.data import api_tweepy as api\n",
    "#Load twitter API credentials and return a tweepy API instance\n",
    "tw_api = api.connect_API('../src/data/twitter_credentials.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.api_tweet_tools import request_user_timeline, batch_request_user_timeline\n",
    "cyber_test_api = batch_request_user_timeline(tw_api, journo_handles, '../data/processed/')\n",
    "# Check\n",
    "cyber_test_api.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Section 4.2: Extract mentions from API tweets<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import data_cleanup as dc\n",
    "# from the API dataset, extract mentions based on tweet id and save in a separate csv\n",
    "mentions_api  = dc.mentions_to_df(cyber_test_api)\n",
    "# Check\n",
    "mentions_api.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions_api.to_csv('../data/processed/' + keyword + '_mentions_api.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Section 5. Data cleaning and standardization/LDA<h3>\n",
    "     <h4>Section 5.1: Clean and standardize Twint dataset<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/S2DS/GitHub/Aug20_Ditchley/src/data/data_cleanup.py:148: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  standard_df = pd.concat([standard_df, twint_df[twint_df.columns.intersection(standard_df.columns)]], axis=0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>like_count</th>\n",
       "      <th>name</th>\n",
       "      <th>quoted_status</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>replies_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>rt_id</th>\n",
       "      <th>rt_screen_name</th>\n",
       "      <th>rt_text</th>\n",
       "      <th>rt_user_id</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created_at</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1299059177474732034</td>\n",
       "      <td>['starwars', 'openingnightlive']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[335773502]</td>\n",
       "      <td>0</td>\n",
       "      <td>Lucy Ingham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>_lucyingham</td>\n",
       "      <td>Oh EA, what have you done to #StarWars? And Th...</td>\n",
       "      <td>2020-08-27 21:00:17</td>\n",
       "      <td>1299059177474732034</td>\n",
       "      <td>335773502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1299057580774432770</td>\n",
       "      <td>['openingnightlive']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[335773502]</td>\n",
       "      <td>1</td>\n",
       "      <td>Lucy Ingham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>_lucyingham</td>\n",
       "      <td>We need more diversity in video game show pres...</td>\n",
       "      <td>2020-08-27 20:53:57</td>\n",
       "      <td>1299057580774432770</td>\n",
       "      <td>335773502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1298282082746216449</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[335773502, 1244308848, 26069433]</td>\n",
       "      <td>2</td>\n",
       "      <td>Lucy Ingham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>_lucyingham</td>\n",
       "      <td>You're going to have to give us a training ses...</td>\n",
       "      <td>2020-08-25 17:53:48</td>\n",
       "      <td>1298287471004983296</td>\n",
       "      <td>335773502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1298131556251262976</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[335773502, 4385491]</td>\n",
       "      <td>1</td>\n",
       "      <td>Lucy Ingham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>_lucyingham</td>\n",
       "      <td>Ah sorry looks like they've changed the option...</td>\n",
       "      <td>2020-08-25 08:12:15</td>\n",
       "      <td>1298141120128524288</td>\n",
       "      <td>335773502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1298131556251262976</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[335773502, 4385491]</td>\n",
       "      <td>2</td>\n",
       "      <td>Lucy Ingham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>_lucyingham</td>\n",
       "      <td>On Google Drive, have you set link sharing to ...</td>\n",
       "      <td>2020-08-25 07:53:41</td>\n",
       "      <td>1298136447258697728</td>\n",
       "      <td>335773502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       conversation_id                          hashtags  \\\n",
       "0  1299059177474732034  ['starwars', 'openingnightlive']   \n",
       "1  1299057580774432770              ['openingnightlive']   \n",
       "2  1298282082746216449                                []   \n",
       "3  1298131556251262976                                []   \n",
       "4  1298131556251262976                                []   \n",
       "\n",
       "   in_reply_to_screen_name in_reply_to_status_id  \\\n",
       "0                      NaN                   NaN   \n",
       "1                      NaN                   NaN   \n",
       "2                      NaN                   NaN   \n",
       "3                      NaN                   NaN   \n",
       "4                      NaN                   NaN   \n",
       "\n",
       "                 in_reply_to_user_id  like_count         name quoted_status  \\\n",
       "0                        [335773502]           0  Lucy Ingham           NaN   \n",
       "1                        [335773502]           1  Lucy Ingham           NaN   \n",
       "2  [335773502, 1244308848, 26069433]           2  Lucy Ingham           NaN   \n",
       "3               [335773502, 4385491]           1  Lucy Ingham           NaN   \n",
       "4               [335773502, 4385491]           2  Lucy Ingham           NaN   \n",
       "\n",
       "   quoted_status_id replies_count  retweet_count rt_id rt_screen_name rt_text  \\\n",
       "0               NaN             0              0   NaN            NaN     NaN   \n",
       "1               NaN             0              0   NaN            NaN     NaN   \n",
       "2               NaN             1              0   NaN            NaN     NaN   \n",
       "3               NaN             1              0   NaN            NaN     NaN   \n",
       "4               NaN             1              0   NaN            NaN     NaN   \n",
       "\n",
       "  rt_user_id  screen_name                                               text  \\\n",
       "0        NaN  _lucyingham  Oh EA, what have you done to #StarWars? And Th...   \n",
       "1        NaN  _lucyingham  We need more diversity in video game show pres...   \n",
       "2        NaN  _lucyingham  You're going to have to give us a training ses...   \n",
       "3        NaN  _lucyingham  Ah sorry looks like they've changed the option...   \n",
       "4        NaN  _lucyingham  On Google Drive, have you set link sharing to ...   \n",
       "\n",
       "      tweet_created_at             tweet_id    user_id  \n",
       "0  2020-08-27 21:00:17  1299059177474732034  335773502  \n",
       "1  2020-08-27 20:53:57  1299057580774432770  335773502  \n",
       "2  2020-08-25 17:53:48  1298287471004983296  335773502  \n",
       "3  2020-08-25 08:12:15  1298141120128524288  335773502  \n",
       "4  2020-08-25 07:53:41  1298136447258697728  335773502  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardise the twint output \n",
    "from src.data import data_cleanup as dc\n",
    "\n",
    "# Standardize Twint dataset for graph DB loading\n",
    "standard_tweet_twint = dc.clean_twint_dataframe(cyber_test)\n",
    "# Check\n",
    "standard_tweet_twint.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe\n",
    "standard_tweet_twint.to_csv('../data/processed/' + keyword + '_standard_tweets_twint.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Section 5.2: Clean and standardize API dataset<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise the twint output \n",
    "from src.data import data_cleanup as dc\n",
    "\n",
    "# Standardize API dataset for graph DB loading\n",
    "standard_tweet_api = dc.clean_API_dataframe(cyber_test_api)\n",
    "# Check\n",
    "standard_tweet_api.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe\n",
    "standard_tweet_api.to_csv('../data/processed/' + keyword + '_standard_tweets_api.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Section 6. Create graph database and import twitter data into it<h3>\n",
    "    <h4>Section 6.1: Import modules and load graph database<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph database=<Database uri='bolt://localhost:7687' secure=False user_agent='py2neo/4.3.0 neobolt/1.7.17 Python/3.6.4-final-0 (darwin)'> name='data'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from py2neo import Graph\n",
    "from py2neo.data import Node, Relationship\n",
    "from src.graph_database import graphdb as gdb\n",
    "\n",
    "# load / declare the database\n",
    "graph = gdb.get_graph(new_graph = True)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Section 6.2: Load user info into graph DB<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in user information and drawing (Person) nodes\n"
     ]
    }
   ],
   "source": [
    "# Neo4j import files need to be in a specific folder, however, the csv files saved above are in a different folder, to go around this problem on Windows machines it is\n",
    "# possible to create a shortcut between the two folders\n",
    "\n",
    "# lowd in user information\n",
    "print('Loading in user information and drawing (Person) nodes')\n",
    "fn_users = 'processed/'+keyword+'_user_profiles.csv'\n",
    "gdb.load_users(fn_users ,graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Section 6.2: Load friend information into DB<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in friends info and drawing [FOLLOWS] edges\n"
     ]
    }
   ],
   "source": [
    "# load in friend information\n",
    "print('Loading in friends info and drawing [FOLLOWS] edges')\n",
    "fn_friends = 'processed/'+keyword+'_journalist_friends.csv'\n",
    "gdb.load_friends(fn_friends,graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Section 6.3: Load tweet data into DB<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in tweets and drawing (Tweet) nodes\n"
     ]
    }
   ],
   "source": [
    "# load in tweet information from twint\n",
    "print('Loading in tweets and drawing (Tweet) nodes')\n",
    "fn_tweets = 'processed/'+keyword+'_standard_tweets_twint.csv'\n",
    "gdb.load_tweets(fn_tweets ,graph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in tweet information from API\n",
    "print('Loading in tweets and drawing (Tweet) nodes')\n",
    "fn_tweets = 'processed/'+keyword+'_standard_tweets_api.csv'\n",
    "gdb.load_tweets(fn_tweets ,graph) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Section 6.4: Draw edges between users and their tweets<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drawing [POSTS] edges\n"
     ]
    }
   ],
   "source": [
    "# draw edges between users and their tweets\n",
    "print('Drawing [POSTS] edges')\n",
    "gdb.get_posts(graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Section 6.5: Load tweets' mentions<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in mentions and drawing [MENTIONS] edges\n"
     ]
    }
   ],
   "source": [
    "# load in mentions information\n",
    "print('Loading in mentions and drawing [MENTIONS] edges')\n",
    "fn_mentions = 'processed/'+keyword+'_mentions_twint.csv'\n",
    "gdb.load_mentions(fn_mentions,graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw TALKS_ABOUT edges between users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb.get_talk_about_edges(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Section 6.6: Run page rank algorithm using [FOLLOWS] [MENTIONS] edges<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running page rank\n"
     ]
    }
   ],
   "source": [
    "# run Page rank using follower and mention edges\n",
    "print('running page rank')\n",
    "nodelist = ['Person']\n",
    "edgelist = ['FOLLOWS']\n",
    "page_rank = gdb.run_pagerank(nodelist,edgelist,graph,new_native_graph=True)\n",
    "\n",
    "#df = pd.DataFrame.from_records(page_rank)#, columns=['screen name', 'rank', 'n_followers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       screen name      rank n_followers\n",
      "0  securitycharlie  0.151544       10825\n",
      "1        fisher85m  0.151544       87951\n",
      "2          gcluley  0.151544       97889\n",
      "3     bsideslondon  0.151302        8071\n",
      "4     ronaldvdmeer  0.151302        8298\n",
      "5     ellieturnell  0.150939         110\n",
      "6   realsexycyborg  0.150939      137934\n",
      "7      kim_crawley  0.150939       15553\n",
      "8        antgrasso  0.150939      157070\n",
      "9  drjessicabarker  0.150939       16017\n"
     ]
    }
   ],
   "source": [
    "unboosted_top_10_follows = page_rank[:10]\n",
    "print(unboosted_top_10_follows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running page rank\n",
      "      screen name      rank n_followers\n",
      "0       intel_owl  0.213750        None\n",
      "1      matte_lodi  0.213750        None\n",
      "2  blackhatevents  0.164167      279667\n",
      "3       albinowax  0.164167       30127\n",
      "4       safetydet  0.164167         370\n",
      "5       dailyswig  0.164167        4994\n",
      "6       joelgmsec  0.164167         904\n",
      "7     consequence  0.164167        None\n",
      "8    mcrmetrolink  0.164167        None\n",
      "9   nailheadparty  0.164167        None\n"
     ]
    }
   ],
   "source": [
    "print('running page rank')\n",
    "nodelist = ['Person']\n",
    "edgelist = ['TALKS_ABOUT']\n",
    "page_rank = gdb.run_pagerank(nodelist,edgelist,graph,new_native_graph=True)\n",
    "unboosted_top_10_talks_about = page_rank[:10]\n",
    "print(unboosted_top_10_talks_about)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Section 6.7: Get a weighted random sample from the journalists friends<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a weighted random sample of users\n",
    "n_sample = 20\n",
    "fields = ['rank']\n",
    "exponents = [2]\n",
    "sample = gdb.get_multiple_weighted_sample(page_rank,n_sample,fields,exponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen name</th>\n",
       "      <th>rank</th>\n",
       "      <th>n_followers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>micleadership</td>\n",
       "      <td>0.150242</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>kevinmitnick</td>\n",
       "      <td>0.150242</td>\n",
       "      <td>251710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>windows</td>\n",
       "      <td>0.150605</td>\n",
       "      <td>6287423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>blissfoster</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>jessrobin96</td>\n",
       "      <td>0.150242</td>\n",
       "      <td>4442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mcafee</td>\n",
       "      <td>0.150847</td>\n",
       "      <td>116282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>zahrasalmanasif</td>\n",
       "      <td>0.150697</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>mmurray</td>\n",
       "      <td>0.150605</td>\n",
       "      <td>9571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>edwardsclm</td>\n",
       "      <td>0.150697</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>patrickwardle</td>\n",
       "      <td>0.150242</td>\n",
       "      <td>23739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         screen name      rank n_followers\n",
       "512    micleadership  0.150242         179\n",
       "568     kevinmitnick  0.150242      251710\n",
       "355          windows  0.150605     6287423\n",
       "827      blissfoster  0.150000        None\n",
       "671      jessrobin96  0.150242        4442\n",
       "26            mcafee  0.150847      116282\n",
       "234  zahrasalmanasif  0.150697         734\n",
       "384          mmurray  0.150605        9571\n",
       "139       edwardsclm  0.150697         215\n",
       "559    patrickwardle  0.150242       23739"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boost graph to flesh out connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boost iteration  1\n",
      "Attempt #1 to get friends of @hart_jason\n",
      "Attempt #1 to get friends of @cedyuen\n",
      "Attempt #1 to get friends of @airosecurity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n",
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n",
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n",
      "CRITICAL:root:twint.feed:Follow:IndexError\n",
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt #2 to get friends of @cedyuen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.feed:Follow:IndexError\n",
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt #3 to get friends of @cedyuen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.feed:Follow:IndexError\n",
      "CRITICAL:root:twint.feed:Follow:IndexError\n",
      "CRITICAL:root:twint.feed:Follow:IndexError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for @airosecurity saved to: ../data/raw/cybersecurity_friends_airosecurity.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.feed:Follow:IndexError\n",
      "CRITICAL:root:twint.feed:Follow:IndexError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for @hart_jason saved to: ../data/raw/cybersecurity_friends_hart_jason.csv\n",
      "@hart_jason follows 1100 users.\n",
      "@airosecurity follows 598 users.\n",
      "\n",
      "Total number of handles pulled: 1698\n",
      "Number of unique twitter handles: 1629\n",
      "\n",
      "Zero following in list for users: ['cedyuen']\n",
      "boost iteration  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt #1 to get friends of @dmbisson\n",
      "Attempt #1 to get friends of @denisemberard\n",
      "Attempt #1 to get friends of @sambowne\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n",
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n",
      "CRITICAL:root:twint.feed:Follow:IndexError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt #2 to get friends of @sambowne\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n",
      "CRITICAL:root:twint.feed:Follow:IndexError\n",
      "CRITICAL:root:twint.feed:Follow:IndexError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for @sambowne saved to: ../data/raw/cybersecurity_friends_sambowne.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.feed:Follow:IndexError\n",
      "CRITICAL:root:twint.feed:Follow:IndexError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for @denisemberard saved to: ../data/raw/cybersecurity_friends_denisemberard.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.feed:Follow:IndexError\n",
      "CRITICAL:root:twint.feed:Follow:IndexError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for @dmbisson saved to: ../data/raw/cybersecurity_friends_dmbisson.csv\n",
      "@dmbisson follows 8854 users.\n",
      "@denisemberard follows 3051 users.\n",
      "@sambowne follows 1916 users.\n",
      "\n",
      "Total number of handles pulled: 13821\n",
      "Number of unique twitter handles: 12927\n",
      "\n",
      "Zero following in list for users: []\n",
      "boost iteration  3\n",
      "Attempt #1 to get friends of @securitybrew\n",
      "Attempt #1 to get friends of @monkeybanking\n",
      "Attempt #1 to get friends of @cbrreynolds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n",
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n",
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n",
      "CRITICAL:root:twint.feed:Follow:IndexError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt #2 to get friends of @monkeybanking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n",
      "CRITICAL:root:twint.feed:Follow:IndexError\n",
      "CRITICAL:root:twint.feed:Follow:IndexError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for @cbrreynolds saved to: ../data/raw/cybersecurity_friends_cbrreynolds.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.feed:Follow:IndexError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for @securitybrew saved to: ../data/raw/cybersecurity_friends_securitybrew.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.feed:Follow:IndexError\n",
      "CRITICAL:root:twint.feed:Follow:IndexError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for @monkeybanking saved to: ../data/raw/cybersecurity_friends_monkeybanking.csv\n",
      "@securitybrew follows 900 users.\n",
      "@monkeybanking follows 1574 users.\n",
      "@cbrreynolds follows 430 users.\n",
      "\n",
      "Total number of handles pulled: 2904\n",
      "Number of unique twitter handles: 2843\n",
      "\n",
      "Zero following in list for users: []\n"
     ]
    }
   ],
   "source": [
    "niter = 3\n",
    "nsample = 3\n",
    "fields = ['rank']\n",
    "exponents = [2]\n",
    "kwargs = {'n_retries':2,\n",
    "         'suppress':False}\n",
    "\n",
    "pagerank_params = nodelist, edgelist, graph\n",
    "#from src.graph_database import graphdb_dev as gdb\n",
    "gdb.boost_graph(niter,nsample,fields,exponents,pagerank_params,keyword,kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       screen name      rank n_followers\n",
      "0    jesscahaworth  0.187568         668\n",
      "1       joe_carson  0.185095        1847\n",
      "2     dannyjpalmer  0.184818        7436\n",
      "3     sinon_reborn  0.183668       14663\n",
      "4   blackhatevents  0.160634      279675\n",
      "5       briankrebs  0.160634      289034\n",
      "6            k8em0  0.160025       98301\n",
      "7          evacide  0.159076      132924\n",
      "8  swiftonsecurity  0.159076      309475\n",
      "9         symantec  0.158828      206759\n"
     ]
    }
   ],
   "source": [
    "page_rank = gdb.run_pagerank(nodelist,edgelist,graph,new_native_graph=True)\n",
    "boosted_top_10_follows = page_rank[:10]\n",
    "print(boosted_top_10_follows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>securitycharlie</td>\n",
       "      <td>0.151697</td>\n",
       "      <td>10820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fisher85m</td>\n",
       "      <td>0.151697</td>\n",
       "      <td>87927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gcluley</td>\n",
       "      <td>0.151697</td>\n",
       "      <td>97866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bsideslondon</td>\n",
       "      <td>0.151420</td>\n",
       "      <td>8066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ronaldvdmeer</td>\n",
       "      <td>0.151420</td>\n",
       "      <td>8297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ellieturnell</td>\n",
       "      <td>0.151011</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>realsexycyborg</td>\n",
       "      <td>0.151011</td>\n",
       "      <td>137800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kim_crawley</td>\n",
       "      <td>0.151011</td>\n",
       "      <td>15485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>antgrasso</td>\n",
       "      <td>0.151011</td>\n",
       "      <td>156648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>drjessicabarker</td>\n",
       "      <td>0.151011</td>\n",
       "      <td>15957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1       2\n",
       "0  securitycharlie  0.151697   10820\n",
       "1        fisher85m  0.151697   87927\n",
       "2          gcluley  0.151697   97866\n",
       "3     bsideslondon  0.151420    8066\n",
       "4     ronaldvdmeer  0.151420    8297\n",
       "5     ellieturnell  0.151011     111\n",
       "6   realsexycyborg  0.151011  137800\n",
       "7      kim_crawley  0.151011   15485\n",
       "8        antgrasso  0.151011  156648\n",
       "9  drjessicabarker  0.151011   15957"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
